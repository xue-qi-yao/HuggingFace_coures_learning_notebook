{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text embeddings represent text as vectors, we can use metrics like cosine similarity to compare how close tow embeddings are\n",
    "#### However, each token is represented by one vector, we want one vector per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiyaoxue/miniconda3/envs/python3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/qiyaoxue/miniconda3/envs/python3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['last_hidden_state', 'pooler_output']) \n",
      " BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-3.8393e-02, -2.8853e-01,  4.0027e-01,  ...,  3.5841e-01,\n",
      "          -2.9464e-01, -1.3763e-01],\n",
      "         [ 1.0028e-01,  6.0142e-01,  6.0682e-01,  ..., -4.2398e-02,\n",
      "          -1.3764e+00, -8.1835e-01],\n",
      "         [ 3.7000e-01,  9.1386e-01, -1.4837e-02,  ...,  2.8944e-01,\n",
      "          -1.0217e+00,  6.4255e-02],\n",
      "         ...,\n",
      "         [ 3.6804e-01, -5.6256e-01,  3.8511e-01,  ..., -5.2118e-01,\n",
      "          -5.6799e-01,  1.6809e-01],\n",
      "         [ 1.2226e-01,  6.1453e-01,  5.5021e-01,  ...,  5.7623e-01,\n",
      "          -1.1041e+00,  5.8898e-02],\n",
      "         [ 1.6646e-01,  4.3578e-01,  7.0070e-01,  ...,  2.9473e-01,\n",
      "          -5.6696e-01, -2.0016e-01]],\n",
      "\n",
      "        [[-6.2539e-02,  3.6616e-01,  6.2801e-01,  ...,  1.6939e-01,\n",
      "          -2.1909e-01,  7.0204e-02],\n",
      "         [-2.6119e-02,  5.0957e-01,  1.0327e+00,  ..., -8.2783e-01,\n",
      "          -6.0066e-01,  7.5721e-01],\n",
      "         [ 3.2615e-02,  1.4699e-01,  6.3324e-01,  ..., -3.7048e-01,\n",
      "          -8.2069e-04,  2.6971e-01],\n",
      "         ...,\n",
      "         [ 7.5856e-02,  1.8914e-01,  3.0180e-01,  ..., -2.3695e-01,\n",
      "          -3.9142e-02,  1.1894e-01],\n",
      "         [-1.4633e-01, -7.2602e-02,  4.9529e-01,  ...,  2.0878e-01,\n",
      "           1.8754e-02, -1.7342e-01],\n",
      "         [-2.3025e-01, -6.9913e-02,  4.7557e-01,  ...,  2.5194e-01,\n",
      "          -6.1557e-02, -6.8015e-02]],\n",
      "\n",
      "        [[ 4.2827e-01, -1.8307e-01,  2.6087e-01,  ...,  3.0655e-01,\n",
      "          -3.0503e-01,  1.0684e-02],\n",
      "         [ 2.6063e-01,  3.6723e-01,  3.1324e-01,  ..., -3.8806e-02,\n",
      "          -1.1825e+00, -7.0977e-01],\n",
      "         [ 6.2554e-01,  8.9825e-01, -1.0741e-01,  ...,  2.3003e-01,\n",
      "          -1.1040e+00,  8.4338e-02],\n",
      "         ...,\n",
      "         [ 7.1172e-01, -6.0819e-01,  4.2694e-01,  ..., -5.1369e-01,\n",
      "          -6.2959e-01,  1.1795e-01],\n",
      "         [ 3.3654e-01,  3.6755e-01,  4.0061e-01,  ...,  5.2394e-01,\n",
      "          -9.9016e-01,  1.1636e-01],\n",
      "         [ 4.2867e-01,  2.3170e-01,  4.5965e-01,  ...,  2.8988e-01,\n",
      "          -3.8151e-01, -1.1138e-01]]]), pooler_output=tensor([[-0.0630, -0.0055,  0.0822,  ..., -0.0078, -0.0618, -0.0452],\n",
      "        [-0.0834,  0.0058, -0.0140,  ...,  0.0560, -0.1400, -0.0047],\n",
      "        [-0.1139, -0.0349,  0.0416,  ...,  0.0169, -0.1164, -0.0574]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n",
      "Token embedding shape: torch.Size([3, 10, 384])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "sentences = [\n",
    "    \"I took my dog for a walk.\",\n",
    "    \"Today is going to rain.\",\n",
    "    \"I took my cat for a walk.\"\n",
    "]\n",
    "model_ckpt = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)\n",
    "\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "print(model_output.keys(), \"\\n\", model_output)\n",
    "print(f\"Token embedding shape: {model_output.last_hidden_state.shape}\")\n",
    "# [3, 10, 384] represents the [num_sentences, num_tokens, embed_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The sentence vector can be created using mean pooling, the mean is taken on the sentence level by averaging the embedded token value in each sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention mask shape: torch.Size([3, 10]) , tokenized input shape: torch.Size([3, 10]) , model output shape: torch.Size([3, 10, 384])\n",
      "sentence embedding shape: torch.Size([3, 384])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"attention mask shape:\", encoded_input[\"attention_mask\"].shape, \", tokenized input shape:\", encoded_input[\"input_ids\"].shape, \", model output shape:\", model_output.last_hidden_state.shape)\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    expanded_attention_mask = attention_mask.unsqueeze(dim=-1).expand(model_output.last_hidden_state.shape)\n",
    "    return torch.sum(model_output.last_hidden_state * expanded_attention_mask, dim=1) / torch.clamp(expanded_attention_mask.sum(1), min=1e-9)\n",
    "\n",
    "sentence_embedding = mean_pooling(model_output=model_output, attention_mask=encoded_input[\"attention_mask\"])\n",
    "print(f\"sentence embedding shape: {sentence_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999976 0.13776848 0.83245271]\n",
      " [0.13776848 0.99999994 0.1419073 ]\n",
      " [0.83245265 0.1419073  0.99999988]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sentence_embedding = sentence_embedding.numpy()\n",
    "scores = np.zeros((sentence_embedding.shape[0], sentence_embedding.shape[0]))\n",
    "for idx in range(sentence_embedding.shape[0]):\n",
    "    scores[idx, :] = cosine_similarity([sentence_embedding[idx]], sentence_embedding)[0]\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same trick can be applied to measure similarity of query against a corpus of docs\n",
    "<div><img src=\"image/semantic_search.png\" width=400 ></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiyaoxue/miniconda3/envs/python3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers', 'embeddings'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "squad = load_dataset(\"squad\", split=\"validation[:100]\")\n",
    "print(squad)\n",
    "model_ckpt = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = AutoModel.from_pretrained(model_ckpt)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer(text_list, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    encoded_input = {k: v.to(\"cuda\") for k, v in encoded_input.items()}\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    return mean_pooling(model_output=model_output, attention_mask=encoded_input[\"attention_mask\"])\n",
    "\n",
    "squad_with_embeddings = squad.map(lambda x: {\"embeddings\": get_embeddings(x[\"context\"]).cpu().numpy()[0]})\n",
    "# take 0 index as the model output has a starting 1 dimension represent batch\n",
    "print(squad_with_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CBS broadcast Super Bowl 50 in the U.S., and c...</td>\n",
       "      <td>23.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>28.554834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>28.554834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>28.554834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>28.554834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>28.554834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>28.554834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>28.554834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>28.554834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>28.554834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>28.554834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context     scores\n",
       "0   CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "1   CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "2   CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "3   CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "4   CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "5   CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "6   CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "7   CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "8   CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "9   CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "10  CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "11  CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "12  CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "13  CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "14  CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "15  CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "16  CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "17  CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "18  CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "19  CBS broadcast Super Bowl 50 in the U.S., and c...  23.663601\n",
       "20  Super Bowl 50 was an American football game to...  28.554834\n",
       "21  Super Bowl 50 was an American football game to...  28.554834\n",
       "22  Super Bowl 50 was an American football game to...  28.554834\n",
       "23  Super Bowl 50 was an American football game to...  28.554834\n",
       "24  Super Bowl 50 was an American football game to...  28.554834\n",
       "25  Super Bowl 50 was an American football game to...  28.554834\n",
       "26  Super Bowl 50 was an American football game to...  28.554834\n",
       "27  Super Bowl 50 was an American football game to...  28.554834\n",
       "28  Super Bowl 50 was an American football game to...  28.554834\n",
       "29  Super Bowl 50 was an American football game to...  28.554834"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "question = \"Who headlined the halftime show for Super Bowl 50?\"\n",
    "question_embedding = get_embeddings([question]).cpu().detach().numpy()\n",
    "print(question_embedding.shape)\n",
    "\n",
    "scores, samples = squad_with_embeddings.get_nearest_examples(\"embeddings\", question_embedding, k=30)\n",
    "pd.DataFrame(samples[\"context\"]).rename(columns={0:\"context\"}).join(pd.DataFrame(scores).rename(columns={0:\"scores\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
